[[34m2024-06-27T19:39:57.073+0000[0m] {[34mtask_context_logger.py:[0m63} INFO[0m - Task context logging is enabled[0m
[[34m2024-06-27T19:39:57.075+0000[0m] {[34mexecutor_loader.py:[0m235} INFO[0m - Loaded executor: SequentialExecutor[0m
[[34m2024-06-27T19:39:57.143+0000[0m] {[34mscheduler_job_runner.py:[0m796} INFO[0m - Starting the scheduler[0m
[[34m2024-06-27T19:39:57.143+0000[0m] {[34mscheduler_job_runner.py:[0m803} INFO[0m - Processing each file at most -1 times[0m
[[34m2024-06-27T19:39:57.148+0000[0m] {[34mmanager.py:[0m170} INFO[0m - Launched DagFileProcessorManager with pid: 13014[0m
[[34m2024-06-27T19:39:57.150+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T19:39:57.153+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[2024-06-27T19:39:57.194+0000] {manager.py:393} WARNING - Because we cannot use more than 1 thread (parsing_processes = 2) when using sqlite. So we set parallelism to 1.
[[34m2024-06-27T19:44:57.577+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T19:45:26.572+0000[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: one_task_dag.one_task manual__2024-06-27T19:45:25.019212+00:00 [scheduled]>[0m
[[34m2024-06-27T19:45:26.572+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG one_task_dag has 0/16 running and queued tasks[0m
[[34m2024-06-27T19:45:26.572+0000[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: one_task_dag.one_task manual__2024-06-27T19:45:25.019212+00:00 [scheduled]>[0m
[[34m2024-06-27T19:45:26.574+0000[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='one_task_dag', task_id='one_task', run_id='manual__2024-06-27T19:45:25.019212+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-06-27T19:45:26.575+0000[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'one_task_dag', 'one_task', 'manual__2024-06-27T19:45:25.019212+00:00', '--local', '--subdir', 'DAGS_FOLDER/one_task_dag.py'][0m
[[34m2024-06-27T19:45:26.600+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'one_task_dag', 'one_task', 'manual__2024-06-27T19:45:25.019212+00:00', '--local', '--subdir', 'DAGS_FOLDER/one_task_dag.py'][0m
[[34m2024-06-27T19:45:27.918+0000[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /workspaces/AIRFLOW-HANDSON/airflow/dags/one_task_dag.py[0m
[[34m2024-06-27T19:45:28.066+0000[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/usr/local/python/3.10.13/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-06-27T19:45:28.066+0000[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-06-27T19:45:28.077+0000[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-06-27T19:45:28.663+0000[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: one_task_dag.one_task manual__2024-06-27T19:45:25.019212+00:00 [queued]> on host codespaces-ee93ac[0m
[[34m2024-06-27T19:45:29.406+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='one_task_dag', task_id='one_task', run_id='manual__2024-06-27T19:45:25.019212+00:00', try_number=1, map_index=-1)[0m
[[34m2024-06-27T19:45:29.415+0000[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=one_task_dag, task_id=one_task, run_id=manual__2024-06-27T19:45:25.019212+00:00, map_index=-1, run_start_date=2024-06-27 19:45:28.736311+00:00, run_end_date=2024-06-27 19:45:28.975594+00:00, run_duration=0.239283, state=success, executor_state=success, try_number=1, max_tries=0, job_id=3, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-06-27 19:45:26.573465+00:00, queued_by_job_id=2, pid=15716[0m
[[34m2024-06-27T19:45:29.610+0000[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun one_task_dag @ 2024-06-27 19:45:25.019212+00:00: manual__2024-06-27T19:45:25.019212+00:00, state:running, queued_at: 2024-06-27 19:45:25.064024+00:00. externally triggered: True> successful[0m
[[34m2024-06-27T19:45:29.611+0000[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=one_task_dag, execution_date=2024-06-27 19:45:25.019212+00:00, run_id=manual__2024-06-27T19:45:25.019212+00:00, run_start_date=2024-06-27 19:45:26.501017+00:00, run_end_date=2024-06-27 19:45:29.611030+00:00, run_duration=3.110013, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-06-27 19:45:25.019212+00:00, data_interval_end=2024-06-27 19:45:25.019212+00:00, dag_hash=7489e39bf97f5a299c0767774673ccf4[0m
[[34m2024-06-27T19:49:57.971+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T19:50:42.145+0000[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: Two_task_dag.one_task manual__2024-06-27T19:50:41.387158+00:00 [scheduled]>[0m
[[34m2024-06-27T19:50:42.146+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG Two_task_dag has 0/16 running and queued tasks[0m
[[34m2024-06-27T19:50:42.146+0000[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: Two_task_dag.one_task manual__2024-06-27T19:50:41.387158+00:00 [scheduled]>[0m
[[34m2024-06-27T19:50:42.150+0000[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='Two_task_dag', task_id='one_task', run_id='manual__2024-06-27T19:50:41.387158+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2024-06-27T19:50:42.150+0000[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'Two_task_dag', 'one_task', 'manual__2024-06-27T19:50:41.387158+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-06-27T19:50:42.200+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'Two_task_dag', 'one_task', 'manual__2024-06-27T19:50:41.387158+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-06-27T19:50:43.415+0000[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /workspaces/AIRFLOW-HANDSON/airflow/dags/two_task_dag.py[0m
[[34m2024-06-27T19:50:43.569+0000[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/usr/local/python/3.10.13/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-06-27T19:50:43.569+0000[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-06-27T19:50:43.581+0000[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-06-27T19:50:44.294+0000[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: Two_task_dag.one_task manual__2024-06-27T19:50:41.387158+00:00 [queued]> on host codespaces-ee93ac[0m
[[34m2024-06-27T19:50:45.106+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='Two_task_dag', task_id='one_task', run_id='manual__2024-06-27T19:50:41.387158+00:00', try_number=1, map_index=-1)[0m
[[34m2024-06-27T19:50:45.111+0000[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=Two_task_dag, task_id=one_task, run_id=manual__2024-06-27T19:50:41.387158+00:00, map_index=-1, run_start_date=2024-06-27 19:50:44.365081+00:00, run_end_date=2024-06-27 19:50:44.692243+00:00, run_duration=0.327162, state=success, executor_state=success, try_number=1, max_tries=0, job_id=4, pool=default_pool, queue=default, priority_weight=2, operator=BashOperator, queued_dttm=2024-06-27 19:50:42.147459+00:00, queued_by_job_id=2, pid=18171[0m
[[34m2024-06-27T19:50:45.305+0000[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: Two_task_dag.Two_task manual__2024-06-27T19:50:41.387158+00:00 [scheduled]>[0m
[[34m2024-06-27T19:50:45.306+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG Two_task_dag has 0/16 running and queued tasks[0m
[[34m2024-06-27T19:50:45.306+0000[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: Two_task_dag.Two_task manual__2024-06-27T19:50:41.387158+00:00 [scheduled]>[0m
[[34m2024-06-27T19:50:45.308+0000[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='Two_task_dag', task_id='Two_task', run_id='manual__2024-06-27T19:50:41.387158+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2024-06-27T19:50:45.308+0000[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'Two_task_dag', 'Two_task', 'manual__2024-06-27T19:50:41.387158+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-06-27T19:50:45.335+0000[0m] {[34msequential_executor.py:[0m74} INFO[0m - Executing command: ['airflow', 'tasks', 'run', 'Two_task_dag', 'Two_task', 'manual__2024-06-27T19:50:41.387158+00:00', '--local', '--subdir', 'DAGS_FOLDER/two_task_dag.py'][0m
[[34m2024-06-27T19:50:46.470+0000[0m] {[34mdagbag.py:[0m545} INFO[0m - Filling up the DagBag from /workspaces/AIRFLOW-HANDSON/airflow/dags/two_task_dag.py[0m
[[34m2024-06-27T19:50:46.649+0000[0m] {[34mexample_local_kubernetes_executor.py:[0m40} WARNING[0m - Could not import DAGs in example_local_kubernetes_executor.py[0m
Traceback (most recent call last):
  File "/usr/local/python/3.10.13/lib/python3.10/site-packages/airflow/example_dags/example_local_kubernetes_executor.py", line 38, in <module>
    from kubernetes.client import models as k8s
ModuleNotFoundError: No module named 'kubernetes'
[[34m2024-06-27T19:50:46.649+0000[0m] {[34mexample_local_kubernetes_executor.py:[0m41} WARNING[0m - Install Kubernetes dependencies with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-06-27T19:50:46.660+0000[0m] {[34mexample_kubernetes_executor.py:[0m39} WARNING[0m - The example_kubernetes_executor example DAG requires the kubernetes provider. Please install it with: pip install apache-airflow[cncf.kubernetes][0m
[[34m2024-06-27T19:50:47.314+0000[0m] {[34mtask_command.py:[0m426} INFO[0m - Running <TaskInstance: Two_task_dag.Two_task manual__2024-06-27T19:50:41.387158+00:00 [queued]> on host codespaces-ee93ac[0m
[[34m2024-06-27T19:50:53.109+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='Two_task_dag', task_id='Two_task', run_id='manual__2024-06-27T19:50:41.387158+00:00', try_number=1, map_index=-1)[0m
[[34m2024-06-27T19:50:53.113+0000[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=Two_task_dag, task_id=Two_task, run_id=manual__2024-06-27T19:50:41.387158+00:00, map_index=-1, run_start_date=2024-06-27 19:50:47.382876+00:00, run_end_date=2024-06-27 19:50:52.644629+00:00, run_duration=5.261753, state=success, executor_state=success, try_number=1, max_tries=0, job_id=5, pool=default_pool, queue=default, priority_weight=1, operator=BashOperator, queued_dttm=2024-06-27 19:50:45.307063+00:00, queued_by_job_id=2, pid=18194[0m
[[34m2024-06-27T19:50:53.299+0000[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun Two_task_dag @ 2024-06-27 19:50:41.387158+00:00: manual__2024-06-27T19:50:41.387158+00:00, state:running, queued_at: 2024-06-27 19:50:41.446405+00:00. externally triggered: True> successful[0m
[[34m2024-06-27T19:50:53.299+0000[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=Two_task_dag, execution_date=2024-06-27 19:50:41.387158+00:00, run_id=manual__2024-06-27T19:50:41.387158+00:00, run_start_date=2024-06-27 19:50:42.069831+00:00, run_end_date=2024-06-27 19:50:53.299846+00:00, run_duration=11.230015, state=success, external_trigger=True, run_type=manual, data_interval_start=2024-06-27 19:50:41.387158+00:00, data_interval_end=2024-06-27 19:50:41.387158+00:00, dag_hash=47575a1aa20ee01bc3a64cc772ade900[0m
[[34m2024-06-27T19:54:58.132+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T19:59:58.293+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T20:04:58.453+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T20:09:58.612+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T20:14:58.773+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T20:19:58.933+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T20:24:59.092+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T20:29:59.251+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T20:34:59.411+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T20:39:59.497+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T20:44:59.656+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T20:49:59.815+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T20:54:59.891+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T21:00:00.055+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T21:05:00.075+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T21:10:00.335+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T21:15:00.525+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T21:20:00.607+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T21:25:00.796+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T21:30:01.059+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T21:35:01.267+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2024-06-27T21:40:01.341+0000[0m] {[34mscheduler_job_runner.py:[0m1595} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
